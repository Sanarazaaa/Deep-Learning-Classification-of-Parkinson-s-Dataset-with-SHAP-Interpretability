{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbxlN57yrCzEIvZGc2jbxD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanarazaaa/Deep-Learning-Classification-of-Parkinson-s-Dataset-with-SHAP-Interpretability/blob/main/Deep_Learning_Classification_of_Parkinson%E2%80%99s_Dataset_with_SHAP_Interpretability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "data = pd.read_csv(file_name)\n",
        "\n",
        "data = data.drop(columns=[col for col in data.columns if data[col].isnull().sum() == len(data)])\n",
        "\n",
        "target_col = 'Replication'\n",
        "y = data[target_col]\n",
        "\n",
        "if y.dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
        "if target_col in categorical_cols:\n",
        "    categorical_cols.remove(target_col)\n",
        "\n",
        "X_cat = pd.get_dummies(data[categorical_cols])\n",
        "X_num = data.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "X_processed = pd.concat([X_num, X_cat], axis=1)\n",
        "feature_names = X_processed.columns.tolist()\n",
        "\n",
        "X = X_processed.values\n",
        "X = X.astype('float32')\n",
        "y = y.astype('int')\n",
        "\n",
        "print(\"Feature shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n",
        "print(\"Target unique values:\", np.unique(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, predicted_classes)\n",
        "cr = classification_report(y_test, predicted_classes)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Classification Report:\\n\", cr)\n",
        "\n",
        "print(\"First 10 Predictions:\", predicted_classes[:10])\n",
        "print(\"First 10 True labels:\", y_test[:10])"
      ],
      "metadata": {
        "id": "zebHa2oIjpg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code plots multi-class ROC curves for the trained neural network.\n",
        "It binarizes the test labels, predicts class probabilities, and computes\n",
        "the false positive rate (FPR), true positive rate (TPR), and area under\n",
        "the curve (AUC) for each class. The ROC curves visualize the model's\n",
        "discriminative ability across all classes.**\n",
        "\n"
      ],
      "metadata": {
        "id": "MB2yZx5JiosQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
        "pred_prob = model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(y_test_bin.shape[1]):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], pred_prob[:, i])\n",
        "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc(fpr,tpr):.2f})')\n",
        "\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multi-class ROC Curves')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wvRkr4QtsdXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code performs a t-SNE projection of the dataset to visualize high-dimensional features\n",
        "in 2D space. Each class is plotted with a different color to explore clustering patterns\n",
        "and separability between classes.**"
      ],
      "metadata": {
        "id": "bXcia3Dti9LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "X_embedded = TSNE(n_components=2, random_state=42).fit_transform(X)\n",
        "plt.figure(figsize=(8,6))\n",
        "for class_val in np.unique(y):\n",
        "    idx = np.where(y==class_val)\n",
        "    plt.scatter(X_embedded[idx,0], X_embedded[idx,1], label=f'Class {class_val}')\n",
        "plt.legend()\n",
        "plt.title('t-SNE Projection of Parkinson\\'s Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HC4Vesa-ssbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code trains a Random Forest classifier on the dataset to compute feature importance.\n",
        "It identifies which features contribute most to the model's predictions and optionally\n",
        "visualizes them with a horizontal bar plot.**"
      ],
      "metadata": {
        "id": "g1CfBAHGjNVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "for i, v in enumerate(importances):\n",
        "    print(f\"{feature_names[i]}: {v:.4f}\")\n",
        "\n",
        "# Optional: plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.barh(feature_names, importances)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"Random Forest Feature Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C6i0z8bVtBsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code applies SHAP (SHapley Additive exPlanations) to interpret the neural network's\n",
        "predictions. It computes SHAP values for a subset of test samples and visualizes the\n",
        "impact of each feature on the model's outputs using a summary plot.**"
      ],
      "metadata": {
        "id": "WkZ_kfyijVvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer = shap.KernelExplainer(model.predict, X_train[:50])  # smaller sample for speed\n",
        "shap_values = explainer.shap_values(X_test[:20])\n",
        "\n",
        "shap.summary_plot(shap_values, X_test[:20], feature_names=feature_names)\n"
      ],
      "metadata": {
        "id": "PhObQZoMtSNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code trains the neural network with early stopping to prevent overfitting.\n",
        "Training stops if the validation loss does not improve for a specified number of epochs,\n",
        "and the model restores the best weights observed during training.**"
      ],
      "metadata": {
        "id": "PlvBZeybjjwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=16, callbacks=[early_stop])\n"
      ],
      "metadata": {
        "id": "Kv99MJoutW4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code prepares the true and predicted labels for multi-class ROC/AUC evaluation.\n",
        "It binarizes the test labels and obtains predicted probabilities from the neural network\n",
        "to compute ROC curves and AUC scores for each class.**"
      ],
      "metadata": {
        "id": "oJScLI-ijr-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
        "y_pred_bin = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "psU9DRT8tZTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c19366-a5af-48d6-d76f-e6edde5dfae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i in range(y_test_bin.shape[1]):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i])\n",
        "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc(fpr, tpr):.2f})')\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multi-class ROC Curves')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G7viBn0NkRuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Binarize the test labels\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
        "y_pred_bin = model.predict(X_test)\n",
        "\n",
        "# Compute AUC for each class\n",
        "for i, class_label in enumerate(np.unique(y)):\n",
        "    auc_score = roc_auc_score(y_test_bin[:, i], y_pred_bin[:, i])\n",
        "    print(f\"Class {class_label} AUC: {auc_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "KuYZ1SN5kd-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code prepares the true and predicted labels for multi-class ROC/AUC evaluation.\n",
        "It binarizes the test labels and obtains predicted probabilities from the neural network\n",
        "to compute ROC curves and AUC scores for each class.**"
      ],
      "metadata": {
        "id": "HaeBZ0xVj0cS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da73f705"
      },
      "source": [
        "import nbformat\n",
        "import os\n",
        "\n",
        "# Find the notebook file\n",
        "notebook_filename = None\n",
        "for file in os.listdir('/content/'):\n",
        "    if file.endswith('.ipynb'):\n",
        "        notebook_filename = '/content/' + file\n",
        "        break\n",
        "\n",
        "if notebook_filename:\n",
        "    # Load the current notebook\n",
        "    nb = nbformat.read(notebook_filename, as_version=5)\n",
        "\n",
        "    # Remove broken widget metadata\n",
        "    if 'widgets' in nb['metadata']:\n",
        "        nb['metadata'].pop('widgets')\n",
        "\n",
        "    # Save cleaned notebook\n",
        "    nbformat.write(nb, notebook_filename)\n",
        "    print(\"Cleaned notebook saved.\")\n",
        "else:\n",
        "    print(\"Notebook file not found in /content/\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}